{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo's for AZ-2005\n",
    "\n",
    "Prerequisites:\n",
    "\n",
    "- This demo leverages Polyglot Notebooks extension in VSCode. You can get this [here](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.dotnet-interactive-vscode). This extension brings support for multi-language (C#) notebooks to Visual Studio Code.\n",
    "- Make sure you also have Azure OpenAI resource created, and have deployed a gpt-4o model. Instructions can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal).\n",
    "- Read the documentation for Semantic Kernel [here](https://learn.microsoft.com/en-us/semantic-kernel/).\n",
    "\n",
    "Consider also following resources:\n",
    "\n",
    "- https://learn.microsoft.com/en-us/semantic-kernel/get-started/detailed-samples?pivots=programming-language-csharp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "Here are some nuget packages we need to import. Notice the Microsoft.SemanticKernel version number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget:Microsoft.Extensions.Logging, 8.0.0\"\n",
    "#r \"nuget:Microsoft.Extensions.Logging.Console, 8.0.0\"\n",
    "#r \"nuget:Microsoft.Extensions.Logging.Debug, 8.0.0\"\n",
    "\n",
    "#r \"nuget:Microsoft.SemanticKernel, 1.16.1\"\n",
    "#r \"nuget:Microsoft.SemanticKernel.Plugins.Core, 1.16.2-alpha\"\n",
    "#r \"nuget:dotenv.net, 3.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set/Get Environment variables\n",
    "\n",
    "Make sure you have a .env file created in the root with the following 2 keys:\n",
    "\n",
    "OPENAI_ENDPOINT=https://[your resource]-[region].openai.azure.com/\n",
    "\n",
    "OPENAI_KEY=xxxxxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using dotenv.net;\n",
    "using dotenv.net.Utilities;\n",
    "\n",
    "DotEnv.Load();\n",
    "\n",
    "var openai_endpoint = EnvReader.GetStringValue(\"OPENAI_ENDPOINT\");\n",
    "var openai_key = EnvReader.GetStringValue(\"OPENAI_KEY\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Semantic Kernel\n",
    "\n",
    "The kernel is at the center of your agents. \n",
    "\n",
    "Because the kernel has all of the services and plugins necessary to run both native code and AI services, it is used by nearly every component within the Semantic Kernel SDK to power your agents. This means that if you run any prompt or code in Semantic Kernel, the kernel will always be available to retrieve the necessary services and plugins.\n",
    "\n",
    "When you invoke a prompt from the kernel. When you do so, the kernel will...\n",
    "\n",
    "1. Select the best AI service to run the prompt.\n",
    "2. Build the prompt using the provided prompt template.\n",
    "3. Send the prompt to the AI service.\n",
    "4. Receive and parse the response.\n",
    "5. And finally return the response from the LLM to your application.\n",
    "\n",
    "The Semantic Kernel SDK supports HuggingFace, OpenAI, and Azure OpenAI LLMs. For this example, we use Azure OpenAI. Make sure you have deployed an Azure OpenAI Resource, deployed a model gpt-4o and configured the environment variables\n",
    "\n",
    "Notice below we also add logging as a service to the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using Microsoft.Extensions.DependencyInjection;\n",
    "using Microsoft.Extensions.Logging;\n",
    "using Microsoft.Extensions.Logging.Abstractions;\n",
    "using Microsoft.Extensions.Logging.Console;\n",
    "using Microsoft.SemanticKernel;\n",
    "using Microsoft.SemanticKernel.ChatCompletion;\n",
    "using Microsoft.SemanticKernel.Connectors.OpenAI;\n",
    "using Microsoft.SemanticKernel.Plugins.Core;\n",
    "\n",
    "var builder = Microsoft.SemanticKernel.Kernel.CreateBuilder();\n",
    "builder.AddAzureOpenAIChatCompletion(\n",
    "         \"gpt-4o\",         // Azure OpenAI Deployment Name. Make sure this is correct\n",
    "         openai_endpoint,  // Azure OpenAI Endpoint\n",
    "         openai_key);      // Azure OpenAI Key\n",
    "\n",
    "builder.Services.AddLogging(c => c.AddDebug()\n",
    "                                  .SetMinimumLevel(LogLevel.Trace) // don't do this in production!\n",
    "                                  .AddConsole());\n",
    "      \n",
    "\n",
    "var kernel = builder.Build();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 0: Test that your kernel and endpoint is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"Give me a list of breakfast foods with eggs and cheese\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: Running your first prompt with Semantic Kernel\n",
    "\n",
    "In this first scenario, we try to get an answer from this question. Notice that the LLM does not know anything about my solar panels and instead, gives a very generic answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string request = \"I want to know how much power my solar panels are providing.\";\n",
    "string prompt = $\"What is the intent of this request? {request}\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: Running your first prompt with Semantic Kernel - set Temperature and MaxTokens\n",
    "\n",
    "We can control the answer a bit, by specifying Temperate and MaxTokens\n",
    "\n",
    "- **Temperature**: The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use log probability to automatically increase the temperature until certain thresholds are hit.\n",
    "\n",
    "- **MaxTokens**: The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string request = \"I want to know how much power my solar panels are providing.\";\n",
    "string prompt = $\"What is the intent of this request? {request}\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt, new(new OpenAIPromptExecutionSettings()\n",
    "{\n",
    "    MaxTokens = 10,\n",
    "    Temperature = 0.7\n",
    "}));\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");\n",
    "result.Display();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Improving the prompt with prompt engineering\n",
    "\n",
    "Prompt engineering is crucial because it directly impacts the effectiveness and reliability of the LLM. The goal is to frame questions or tasks in such a way that the AI provides the most accurate, relevant, and contextually appropriate **output**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string request = \"I want to know how much power my solar panels are providing.\";\n",
    "\n",
    "string prompt = @$\"\n",
    "    What is the intent of this request? \n",
    "    {request}\n",
    "    You can choose between GetSolarEnergyToday, GetSolarPower, GetSolarBatteryPercentage, StartChargingCar.\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4: Add structure to the output with formatting\n",
    "\n",
    "Here, we go even one step further and make the output even more predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string request = \"I want to know how much power my solar panels are providing.\";\n",
    "\n",
    "string prompt = prompt = @$\"\n",
    "    Instructions: What is the intent of this request?\n",
    "    Choices: GetSolarEnergyToday, GetSolarPower, GetSolarBatteryPercentage, StartChargingCar.\n",
    "    User Input: {request}\n",
    "    Intent: \";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = @\"\n",
    "Instructions: Identify the from and to destinations and dates from the user's request\n",
    ">User: Can you give me a list of flights from Seattle to Tokyo? I want to travel from March 11 to March 18.\n",
    ">Output: Seattle|Tokyo|03/11/2024|03/18/2024\n",
    "\n",
    ">User: I have a vacation from June 1 to July 22. I want to go to Greece. I live in Chicago.\n",
    ">Output: \";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 5: Even more control over the output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string request = \"I want to know how much power my solar panels are providing.\";\n",
    "\n",
    "string prompt = $$\"\"\"\n",
    "    ## Instructions\n",
    "    Provide the intent of the request using the following format:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"intent\": {intent}\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    ## Choices\n",
    "    You can choose between the following intents:\n",
    "\n",
    "    ```json\n",
    "    [\"GetSolarEnergyToday\", \"GetSolarPower\", \"GetSolarBatteryPercentage\", \"StartChargingCar\"]\n",
    "    ```\n",
    "\n",
    "    ## User Input\n",
    "    The user input is:\n",
    "\n",
    "    ```json\n",
    "    {\n",
    "        \"request\": \"{{request}}\"\n",
    "    }\n",
    "    ```\n",
    "\n",
    "    ## Intent\n",
    "\"\"\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 6: Provide examples with few-shot prompting\n",
    "\n",
    "Few-shot prompting is a technique in AI where a model is given a small number of examples (usually a few) along with the prompt to help it understand the desired output format or context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string request = \"I want to know how much power my solar panels are providing.\";\n",
    "\n",
    "string prompt = @$\"\n",
    "    Instructions: What is the intent of this request?\n",
    "    If you don't know the intent, don't guess; instead respond with \"\"Unknown\"\".\n",
    "    Choices: GetSolarEnergyToday, GetSolarPower, GetSolarBatteryPercentage, StartChargingCar.\n",
    "\n",
    "    User Input: How much energy did my solar panels provide today?\n",
    "    Intent: GetSolarEnergyToday\n",
    "\n",
    "    User Input: Can you start charging my car?\n",
    "    Intent: StartChargingCar\n",
    "\n",
    "    User Input: {request}\n",
    "    Intent: \";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt);\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 7: Chatbot (async)\n",
    "\n",
    "With chat completion, you can simulate a back-and-forth conversation with an AI agent.\n",
    "\n",
    "**Import note**: If you ask follow-up questions, the model does not remember those.\n",
    "\n",
    "Tip: In VSCode, when you run the cell below, it will ask you for input in the command palette (TOP of the window). You can enter following question:\n",
    "\n",
    "\"who was JF Kennedy?\" and a follow up question \"when did he die?\" (observe the answer)\n",
    "\n",
    "There are two main ways to use a chat completion service:\n",
    "\n",
    "- **Non-streaming**: You wait for the service to generate an entire response before returning it to the user.\n",
    "- **Streaming**: Individual chunks of the response are generated and returned to the user as they are created. (as you can observe in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();\n",
    "\n",
    "while (true)\n",
    "{\n",
    "    Console.Write(\"User > \");\n",
    "\n",
    "    var request = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Enter your message (type EXIT to quit):\");\n",
    "\n",
    "    if (request.ToLower() == \"exit\" || String.IsNullOrEmpty(request))\n",
    "    {\n",
    "        break;\n",
    "    }\n",
    "\n",
    "    Console.Write(request);\n",
    "    Console.WriteLine();\n",
    "\n",
    "    var result = chatCompletionService.GetStreamingChatMessageContentsAsync(request, kernel: kernel);\n",
    "\n",
    "    string fullMessage = \"\";\n",
    "    Console.Write(\"Assistant > \");\n",
    "\n",
    "    await foreach (var content in result)\n",
    "    {\n",
    "        Console.Write(content.Content);\n",
    "        fullMessage += content.Content;\n",
    "    }\n",
    "\n",
    "    Console.WriteLine();\n",
    "    Console.WriteLine();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 8: Chatbot (async, with history)\n",
    "\n",
    "The chat history object is used to maintain a record of messages in a chat session. It is used to store messages from different authors, such as users, assistants, tools, or the system. As the primary mechanism for sending and receiving messages, the chat history object is essential for maintaining context and continuity in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "ChatHistory history = [];   // add chatHistory\n",
    "\n",
    "var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();\n",
    "\n",
    "while (true)\n",
    "{\n",
    "    Console.Write(\"User > \");\n",
    "\n",
    "    var request = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Enter your message (type EXIT to quit):\");\n",
    "\n",
    "    if (request.ToLower() == \"exit\" || String.IsNullOrEmpty(request))\n",
    "    {\n",
    "        break;\n",
    "    }\n",
    "\n",
    "    history.AddUserMessage(request!);       // add user message to history  \n",
    "\n",
    "    Console.Write(request);\n",
    "    Console.WriteLine();\n",
    "\n",
    "    var result = chatCompletionService.GetStreamingChatMessageContentsAsync(history, kernel: kernel);  // replace request with history\n",
    "\n",
    "    string fullMessage = \"\";\n",
    "    Console.Write(\"Assistant > \");\n",
    "\n",
    "    await foreach (var content in result)\n",
    "    {\n",
    "        Console.Write(content.Content);\n",
    "        fullMessage += content.Content;\n",
    "    }\n",
    "\n",
    "    history.AddAssistantMessage(fullMessage);  // add assistant message to history\n",
    "\n",
    "    Console.WriteLine();\n",
    "    Console.WriteLine();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 9: Chatbot (async, with history and a persona)\n",
    "\n",
    "Often called a \"meta prompt\" or \"instruction\", the persona is a prompt that is used to influence how the agent responds to stimuli. This allows you to influence how your agents plan tasks, generate responses, and interact with users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "ChatHistory history = [];   // add chatHistory\n",
    "\n",
    "history.AddSystemMessage($\"You should answer as a 10-year old child. In addition, greet the user by his name: {Environment.UserName}\"); // add a persona\n",
    "\n",
    "var chatCompletionService = kernel.GetRequiredService<IChatCompletionService>();\n",
    "\n",
    "while (true)\n",
    "{\n",
    "    Console.Write(\"User > \");\n",
    "\n",
    "    var request = await Microsoft.DotNet.Interactive.Kernel.GetInputAsync(\"Enter your message (type EXIT to quit):\");\n",
    "\n",
    "    if (request.ToLower() == \"exit\" || String.IsNullOrEmpty(request))\n",
    "    {\n",
    "        break;\n",
    "    }\n",
    "\n",
    "    history.AddUserMessage(request!);       // add user message to history  \n",
    "\n",
    "    Console.Write(request);\n",
    "    Console.WriteLine();\n",
    "\n",
    "    var result = chatCompletionService.GetStreamingChatMessageContentsAsync(history, kernel: kernel);  // replace request with history\n",
    "\n",
    "    string fullMessage = \"\";\n",
    "    Console.Write(\"Assistant > \");\n",
    "\n",
    "    await foreach (var content in result)\n",
    "    {\n",
    "        Console.Write(content.Content);\n",
    "        fullMessage += content.Content;\n",
    "    }\n",
    "\n",
    "    history.AddAssistantMessage(fullMessage);  // add assistant message to history\n",
    "\n",
    "    Console.WriteLine();\n",
    "    Console.WriteLine();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 10: Plugins from Microsoft.SemanticKernel.Plugins.Core (1.16.2-alpha)\n",
    "\n",
    "Plugins are a key component of Semantic Kernel. If you have already used plugins from ChatGPT or Copilot extensions in Microsoft 365, you’re already familiar with them. With plugins, you can encapsulate your existing APIs into a collection that can be used by an AI. This allows you to give your AI the ability to perform actions that it wouldn’t be able to do otherwise.\n",
    "\n",
    "Behind the scenes, Semantic Kernel leverages function calling, a native feature of most of the latest LLMs to allow LLMs, to perform planning and to invoke your APIs. With function calling, LLMs can request (i.e., call) a particular function. Semantic Kernel then marshals the request to the appropriate function in your codebase and returns the results back to the LLM so the LLM can generate a final response.\n",
    "\n",
    "Following plugins are available in this session:\n",
    "- ConversationSummaryPlugin\n",
    "- FileIOPlugin\n",
    "- HttpPlugin\n",
    "- MathPlugin\n",
    "- TextPlugin\n",
    "- TimePlugin\n",
    "- WaitPlugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "#pragma warning disable SKEXP0050 // Type is for evaluation purposes only and is subject to change or removal in future updates. Suppress this diagnostic to proceed.\n",
    "\n",
    "KernelPlugin conversationSummaryPlugin = kernel.Plugins.AddFromType<ConversationSummaryPlugin>();\n",
    "KernelPlugin fileIOPlugin = kernel.Plugins.AddFromType<FileIOPlugin>();\n",
    "KernelPlugin httpPlugin = kernel.Plugins.AddFromType<HttpPlugin>();\n",
    "KernelPlugin mathPlugin = kernel.Plugins.AddFromType<MathPlugin>();\n",
    "KernelPlugin textPlugin = kernel.Plugins.AddFromType<TextPlugin>();\n",
    "KernelPlugin timePlugin = kernel.Plugins.AddFromType<TimePlugin>();\n",
    "KernelPlugin waitPlugin = kernel.Plugins.AddFromType<WaitPlugin>();\n",
    "\n",
    "#pragma warning restore SKEXP0050 // Type is for evaluation purposes only and is subject to change or removal in future updates. Suppress this diagnostic to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "var executionSettings = new OpenAIPromptExecutionSettings\n",
    "{\n",
    "    ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "private const string ChatTranscript =\n",
    "        @\"\n",
    "John: Hello, how are you?\n",
    "Jane: I'm fine, thanks. How are you?\n",
    "John: I'm doing well, writing some example code.\n",
    "Jane: That's great! I'm writing some example code too.\n",
    "John: What are you writing?\n",
    "Jane: I'm writing a chatbot.\n",
    "John: That's cool. I'm writing a chatbot too.\n",
    "Jane: What language are you writing it in?\n",
    "John: I'm writing it in C#.\n",
    "Jane: I'm writing it in Python.\n",
    "John: That's cool. I need to learn Python.\n",
    "Jane: I need to learn C#.\n",
    "John: Can I try out your chatbot?\n",
    "Jane: Sure, here's the link.\n",
    "John: Thanks!\n",
    "Jane: You're welcome.\n",
    "Jane: Look at this poem my chatbot wrote:\n",
    "Jane: Roses are red\n",
    "Jane: Violets are blue\n",
    "Jane: I'm writing a chatbot\n",
    "Jane: What about you?\n",
    "John: That's cool. Let me see if mine will write a poem, too.\n",
    "John: Here's a poem my chatbot wrote:\n",
    "John: The singularity of the universe is a mystery.\n",
    "John: The universe is a mystery.\n",
    "John: The universe is a mystery.\n",
    "John: The universe is a mystery.\n",
    "John: Looks like I need to improve mine, oh well.\n",
    "Jane: You might want to try using a different model.\n",
    "Jane: I'm using the GPT-3 model.\n",
    "John: I'm using the GPT-2 model. That makes sense.\n",
    "John: Here is a new poem after updating the model.\n",
    "John: The universe is a mystery.\n",
    "John: The universe is a mystery.\n",
    "John: The universe is a mystery.\n",
    "John: Yikes, it's really stuck isn't it. Would you help me debug my code?\n",
    "Jane: Sure, what's the problem?\n",
    "John: I'm not sure. I think it's a bug in the code.\n",
    "Jane: I'll take a look.\n",
    "Jane: I think I found the problem.\n",
    "Jane: It looks like you're not passing the right parameters to the model.\n",
    "John: Thanks for the help!\n",
    "Jane: I'm now writing a bot to summarize conversations. I want to make sure it works when the conversation is long.\n",
    "John: So you need to keep talking with me to generate a long conversation?\n",
    "Jane: Yes, that's right.\n",
    "John: Ok, I'll keep talking. What should we talk about?\n",
    "Jane: I don't know, what do you want to talk about?\n",
    "John: I don't know, it's nice how CoPilot is doing most of the talking for us. But it definitely gets stuck sometimes.\n",
    "Jane: I agree, it's nice that CoPilot is doing most of the talking for us.\n",
    "Jane: But it definitely gets stuck sometimes.\n",
    "John: Do you know how long it needs to be?\n",
    "Jane: I think the max length is 1024 tokens. Which is approximately 1024*4= 4096 characters.\n",
    "John: That's a lot of characters.\n",
    "Jane: Yes, it is.\n",
    "John: I'm not sure how much longer I can keep talking.\n",
    "Jane: I think we're almost there. Let me check.\n",
    "Jane: I have some bad news, we're only half way there.\n",
    "John: Oh no, I'm not sure I can keep going. I'm getting tired.\n",
    "Jane: I'm getting tired too.\n",
    "John: Maybe there is a large piece of text we can use to generate a long conversation.\n",
    "Jane: That's a good idea. Let me see if I can find one. Maybe Lorem Ipsum?\n",
    "John: Yeah, that's a good idea.\n",
    "Jane: I found a Lorem Ipsum generator.\n",
    "Jane: Here's a 4096 character Lorem Ipsum text:\n",
    "Jane: Lorem ipsum dolor sit amet, con\n",
    "Jane: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed euismod, nunc sit amet aliquam\n",
    "Jane: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed euismod, nunc sit amet aliquam\n",
    "Jane: Darn, it's just repeating stuff now.\n",
    "John: I think we're done.\n",
    "Jane: We're not though! We need like 1500 more characters.\n",
    "John: Oh Cananda, our home and native land.\n",
    "Jane: True patriot love in all thy sons command.\n",
    "John: With glowing hearts we see thee rise.\n",
    "Jane: The True North strong and free.\n",
    "John: From far and wide, O Canada, we stand on guard for thee.\n",
    "Jane: God keep our land glorious and free.\n",
    "John: O Canada, we stand on guard for thee.\n",
    "Jane: O Canada, we stand on guard for thee.\n",
    "Jane: That was fun, thank you. Let me check now.\n",
    "Jane: I think we need about 600 more characters.\n",
    "John: Oh say can you see?\n",
    "Jane: By the dawn's early light.\n",
    "John: What so proudly we hailed.\n",
    "Jane: At the twilight's last gleaming.\n",
    "John: Whose broad stripes and bright stars.\n",
    "Jane: Through the perilous fight.\n",
    "John: O'er the ramparts we watched.\n",
    "Jane: Were so gallantly streaming.\n",
    "John: And the rockets' red glare.\n",
    "Jane: The bombs bursting in air.\n",
    "John: Gave proof through the night.\n",
    "Jane: That our flag was still there.\n",
    "John: Oh say does that star-spangled banner yet wave.\n",
    "Jane: O'er the land of the free.\n",
    "John: And the home of the brave.\n",
    "Jane: Are you a Seattle Kraken Fan?\n",
    "John: Yes, I am. I love going to the games.\n",
    "Jane: I'm a Seattle Kraken Fan too. Who is your favorite player?\n",
    "John: I like watching all the players, but I think my favorite is Matty Beniers.\n",
    "Jane: Yeah, he's a great player. I like watching him too. I also like watching Jaden Schwartz.\n",
    "John: Adam Larsson is another good one. The big cat!\n",
    "Jane: WE MADE IT! It's long enough. Thank you!\n",
    "John: You're welcome. I'm glad we could help. Goodbye!\n",
    "Jane: Goodbye!\n",
    "\";\n",
    "string prompt = $\"Summarize the following content: {ChatTranscript}\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt, new(executionSettings));\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"What is the current time?\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt, new(executionSettings));\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"Can you summarize me the following article? https://en.wikipedia.org/wiki/Triglav_Lakes_Valley\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt, new(executionSettings));\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 11: Writing your own Date and Time plugin\n",
    "\n",
    "The easiest way to provide an AI agent with capabilities that are not natively supported is to wrap native code into a plugin. This allows you to leverage your existing skills as an app developer to extend the capabilities of your AI agents.\n",
    "\n",
    "Behind the scenes, Semantic Kernel will then use the descriptions you provide, along with reflection, to semantically describe the plugin to the AI agent. This allows the AI agent to understand the capabilities of the plugin and how to interact with it.\n",
    "\n",
    "When authoring a plugin, you need to provide the AI agent with the right information to understand the capabilities of the plugin and its functions. This includes:\n",
    "\n",
    "- The name of the plugin\n",
    "- The names of the functions\n",
    "- The descriptions of the functions\n",
    "- The parameters of the functions\n",
    "- The schema of the parameters\n",
    "\n",
    "The value of Semantic Kernel is that it can automatically generate most of this information from the code itself. As a developer, this just means that you must provide the semantic descriptions of the functions and parameters so the AI agent can understand them. If you properly comment and annotate your code, however, you likely already have this information on hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.ComponentModel;\n",
    "\n",
    "public class MyOwnDateAndTimePlugin {\n",
    "    [KernelFunction]\n",
    "    [Description(\"Gets the current time.\")]\n",
    "    public TimeSpan GetTime()\n",
    "    {\n",
    "        return TimeProvider.System.GetLocalNow().TimeOfDay;\n",
    "    }\n",
    "\n",
    "    [KernelFunction]\n",
    "    [Description(\"Gets the current date.\")]\n",
    "    public DateTime GetDate()\n",
    "    {\n",
    "        return TimeProvider.System.GetLocalNow().Date;\n",
    "    }\n",
    "}\n",
    "\n",
    "KernelPlugin myOwnDateAndTimePlugin = kernel.Plugins.AddFromType<MyOwnDateAndTimePlugin>();  // need to add the plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"What is the current time?\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt, new(executionSettings));\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 12: P1 meter power consumption plugin\n",
    "\n",
    "This is a personal example that leverages a P1 meter like this https://www.homewizard.com/p1-meter/. A P1 meter refers to a smart electricity meter used primarily in Belgium and the Netherlands that includes a P1 port, which is a standardized interface. This port allows consumers to access real-time and historical energy consumption data from the smart meter. \n",
    "\n",
    "![image of p1 meter](https://cdn.homewizard.com/wp-content/uploads/2021/11/P1_meter_front-500x500.png)\n",
    "\n",
    "Make sure you have a .env file in the root with following keys:\n",
    "\n",
    "HOMEWIZARD_USERNAME=\n",
    "\n",
    "HOMEWIZARD_PASSWORD=\n",
    "\n",
    "HOMEWIZARD_DONGLEID="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "using System.Net.Http.Headers;\n",
    "using System.Net.Http;\n",
    "using System.Text;\n",
    "using System.Text.Json;\n",
    "\n",
    "public class P1Meter {\n",
    "    private static readonly HttpClient httpClient = new HttpClient();\n",
    "\n",
    "    [KernelFunction]\n",
    "    [Description(\"Gets the current power consumption from the P1 homewizard energy reader\")]\n",
    "    public async Task<int> GetPower()\n",
    "    {\n",
    "        string token = await GetAuthTokenAsync();\n",
    "        int powerConsumption = await GetPowerConsumptionAsync(token);\n",
    "        return powerConsumption;\n",
    "    }\n",
    "\n",
    "    private async Task<string> GetAuthTokenAsync()\n",
    "    {\n",
    "        string url = \"https://api.homewizardeasyonline.com/v1/auth/login\";\n",
    "\n",
    "        string username = Environment.GetEnvironmentVariable(\"HOMEWIZARD_USERNAME\");\n",
    "        string password = Environment.GetEnvironmentVariable(\"HOMEWIZARD_PASSWORD\");\n",
    "        string authorizationHeader = System.Convert.ToBase64String(System.Text.Encoding.UTF8.GetBytes($\"{username}:{password}\"));\n",
    "\n",
    "        httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Basic\", authorizationHeader);\n",
    "\n",
    "        HttpResponseMessage response = await httpClient.GetAsync(url);\n",
    "        response.EnsureSuccessStatusCode();\n",
    "\n",
    "        string responseBody = await response.Content.ReadAsStringAsync();\n",
    "        using JsonDocument doc = JsonDocument.Parse(responseBody);\n",
    "        string token = doc.RootElement.GetProperty(\"token\").GetString();\n",
    "\n",
    "        return token;\n",
    "    }\n",
    "\n",
    "    private async Task<int> GetPowerConsumptionAsync(string token)\n",
    "    {\n",
    "        string dongleID = Environment.GetEnvironmentVariable(\"HOMEWIZARD_DONGLEID\");\n",
    "        string url = \"https://tsdb-reader.homewizard.com/devices/date/recent\";\n",
    "        string payload = $@\"{{\n",
    "            \"\"devices\"\": [\"\"{dongleID}\"\"],\n",
    "            \"\"type\"\": \"\"main_connection\"\",\n",
    "            \"\"values\"\": true,\n",
    "            \"\"wattage\"\": true,\n",
    "            \"\"gb\"\": \"\"1s\"\",\n",
    "            \"\"fill\"\": \"\"previous\"\"\n",
    "        }}\";\n",
    "\n",
    "        httpClient.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(\"Bearer\", token);\n",
    "        httpClient.DefaultRequestHeaders.Accept.Add(new MediaTypeWithQualityHeaderValue(\"application/json\"));\n",
    "\n",
    "        HttpContent content = new StringContent(payload, Encoding.UTF8, \"application/json\");\n",
    "\n",
    "        HttpResponseMessage response = await httpClient.PostAsync(url, content);\n",
    "        response.EnsureSuccessStatusCode();\n",
    "\n",
    "        string responseBody = await response.Content.ReadAsStringAsync();\n",
    "        using JsonDocument doc = JsonDocument.Parse(responseBody);\n",
    "        int powerConsumption = doc.RootElement.GetProperty(\"values\")[1].GetProperty(\"wattage\").GetInt32();\n",
    "\n",
    "        return powerConsumption;\n",
    "    }\n",
    "}\n",
    "\n",
    "KernelPlugin P1MeterPlugin = kernel.Plugins.AddFromType<P1Meter>();  // need to add the plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "vscode": {
     "languageId": "polyglot-notebook"
    }
   },
   "outputs": [],
   "source": [
    "string prompt = \"What is my current power consumption?\";\n",
    "\n",
    "var result = await kernel.InvokePromptAsync(prompt, new(executionSettings));\n",
    "\n",
    "result.ToString().DisplayAs(\"text/markdown\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
